import Ollama from 'openai'

export type MessageContentText = {
  type: 'text'
  text: string
}

export type MessageContentImageUrl = {
  type: 'image_url'
  image_url: { url: string }
}

export type MessageContentComplex =
  | MessageContentText
  | MessageContentImageUrl
  | (Record<string, any> & {
      type?: 'text' | 'image_url' | string
    })

export type MessageContent =
  | string
  | MessageContentComplex
  | MessageContentComplex[]

export interface FunctionCall {
  arguments: string
  name: string
}

interface ModelConfig {
  baseURL: string
  apiKey: string
  modelName: string
}

interface StorageData {
  selectedModel: string
  baseURL: string
  ollamaConfig: ModelConfig
  openaiConfig: ModelConfig
}

type TranslationModel = 'openai' | 'ollama' | 'thirdparty'

const createOllamaApi = (config: ModelConfig): Ollama => {
  return new Ollama({
    baseURL: config.baseURL,
    apiKey: 'ollama',
  })
}

const translateWithOpenAICompatible = async (
  config: ModelConfig,
  text: string,
  prompt: string,
): Promise<string> => {
  try {
    const response = await fetch(`${config.baseURL}/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        Authorization: `Bearer ${config.apiKey}`,
      },
      body: JSON.stringify({
        model: config.modelName,
        messages: [
          { role: 'system', content: prompt },
          { role: 'user', content: text },
        ],
        temperature: 0.3,
        max_tokens: 1000,
      }),
    })

    if (!response.ok) {
      const errorText = await response.text()
      let errorMessage = `HTTP ${response.status}: ${response.statusText}`

      try {
        const errorData = JSON.parse(errorText)
        if (errorData.error?.message) {
          errorMessage = errorData.error.message
        }
      } catch (e) {
        // å¦‚æœä¸æ˜¯ JSON æ ¼å¼ï¼Œä½¿ç”¨åŸå§‹é”™è¯¯æ–‡æœ¬
        errorMessage = errorText || errorMessage
      }

      throw new Error(`OpenAI API é”™è¯¯: ${errorMessage}`)
    }

    const data = await response.json()
    console.log('ğŸ”¥ OpenAI API å“åº”:', data)

    if (!data.choices || !data.choices[0] || !data.choices[0].message) {
      throw new Error('OpenAI API è¿”å›æ ¼å¼é”™è¯¯ï¼šç¼ºå°‘ choices æˆ– message')
    }

    return data.choices[0].message.content || ''
  } catch (error) {
    if (error instanceof Error) {
      throw error
    }
    throw new Error(`OpenAI API è¯·æ±‚å¤±è´¥: ${error}`)
  }
}

const translateWithOllama = async (
  instance: Ollama,
  text: string,
  prompt: string,
  modelName: string,
): Promise<string> => {
  try {
    const response = await fetch(`${instance.baseURL}/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: modelName,
        messages: [
          { role: 'system', content: prompt },
          { role: 'user', content: text },
        ],
        temperature: 0.3,
        stream: false,
      }),
    })

    if (!response.ok) {
      const errorText = await response.text()
      let errorMessage = `HTTP ${response.status}: ${response.statusText}`

      try {
        const errorData = JSON.parse(errorText)
        if (errorData.error) {
          errorMessage = errorData.error
        }
      } catch (e) {
        errorMessage = errorText || errorMessage
      }

      // æä¾›æ›´å‹å¥½çš„é”™è¯¯ä¿¡æ¯
      if (response.status === 404) {
        errorMessage = `æ¨¡å‹ "${modelName}" æœªæ‰¾åˆ°ã€‚è¯·ç¡®ä¿å·²å®‰è£…è¯¥æ¨¡å‹ï¼šollama pull ${modelName}`
      } else if (response.status === 500) {
        errorMessage = `Ollama æœåŠ¡å™¨é”™è¯¯ã€‚è¯·æ£€æŸ¥ Ollama æ˜¯å¦æ­£å¸¸è¿è¡Œï¼šollama serve`
      }

      throw new Error(`Ollama API é”™è¯¯: ${errorMessage}`)
    }

    const data = await response.json()
    console.log('ğŸ”¥ Ollama API å“åº”:', data)

    if (!data.choices || !data.choices[0] || !data.choices[0].message) {
      throw new Error('Ollama API è¿”å›æ ¼å¼é”™è¯¯ï¼šç¼ºå°‘ choices æˆ– message')
    }

    return data.choices[0].message.content || ''
  } catch (error) {
    if (error instanceof Error) {
      throw error
    }
    throw new Error(`Ollama API è¯·æ±‚å¤±è´¥: ${error}`)
  }
}

const getStorageData = (): Promise<StorageData> => {
  return new Promise((resolve) => {
    chrome.storage.local.get(
      ['selectedModel', 'baseURL', 'ollamaConfig', 'openaiConfig'],
      (result) => {
        resolve(result as StorageData)
      },
    )
  })
}

const translateText = async (
  text: string,
  targetLanguage: string,
  prompt: string,
): Promise<string> => {
  try {
    const { selectedModel, ollamaConfig, openaiConfig } = await getStorageData()

    // console.log('Selected model:', selectedModel, ollamaConfig, openaiConfig);

    let result: string

    switch (selectedModel as TranslationModel) {
      case 'openai':
        result = await translateWithOpenAICompatible(openaiConfig, text, prompt)
        break
      case 'ollama':
        const ollamaInstance = createOllamaApi(ollamaConfig)
        result = await translateWithOllama(
          ollamaInstance,
          text,
          prompt,
          ollamaConfig.modelName,
        )
        break
      // case 'thirdparty':
      //     //TODO: Implement third-party API translation here
      //     break;
      default:
        throw new Error('Unsupported model selected')
    }

    return result
  } catch (error) {
    console.error('Error translating text:', error)
    throw new Error('Translation failed')
  }
}

export { translateText }
